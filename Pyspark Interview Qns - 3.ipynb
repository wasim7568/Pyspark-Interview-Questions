{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4995a869-3c34-48cf-a4f5-ad569cb6369d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Rename multiple columns in one line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d6fbaea-c5dc-45f0-9e12-6087968a587c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+------+\n| id| name|gender|salary|\n+---+-----+------+------+\n|  1|Rohit|     M|  4000|\n|  2|Divya|     F|  5000|\n+---+-----+------+------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Rohit', 'M',4000),(2, 'Divya', 'F',5000),(3, 'Sam', 'M',5000),(4, 'Kohli', 'M',4000)]\n",
    "\n",
    "schema = \"id int, name String ,gender String ,salary int\"\n",
    "\n",
    "emp_df = spark.createDataFrame(data, schema)\n",
    "emp_df.show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae04a409-9dd3-428f-8619-07785abebf9a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def rename_multiple_columns(df: DataFrame, nam_dict: dict):\n",
    "    \"\"\"Change the name of different columns, based on a dictionary\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): Data frame which columns will be renamed\n",
    "        name_dict (dict): Python dictionary (key, value pair) with keys being the old column name and the values the new names\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Dataframe with columns renamed\n",
    "    \"\"\"\n",
    "    for key, value in nam_dict.items():\n",
    "        df = df.withColumnRenamed(key, value)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0796d1cf-32a1-4c03-8902-32f89c76d139",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+----------+\n|emp_id|emp_name|gender|upd_salary|\n+------+--------+------+----------+\n|     1|   Rohit|     M|      4000|\n|     2|   Divya|     F|      5000|\n|     3|     Sam|     M|      5000|\n|     4|   Kohli|     M|      4000|\n+------+--------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "rename_multiple_columns(df=emp_df,nam_dict={'id':'emp_id','name':'emp_name','salary':'upd_salary'}).show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Pyspark Interview Qns - 3",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
